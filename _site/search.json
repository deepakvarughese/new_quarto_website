[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr Deepak Varughese, MD",
    "section": "",
    "text": "I am a primary care physician and epidemiologist with experience in rural, tribal and urban settings. I have experience in research design , methodology, data analysis and visualization.\nI believe primary care and family medicine is a powerful piece in the health system. High Quality Primary Care can improve access to care and ensure effective follow up. My areas of clinical interest include chronic disease care, palliative medicine and rehabilitation.\nI believe that my experience in clinical medicine along with skills in epidemiology, biostatistics and programming give me a unique combination of skills to ask relevant questions, collect relevant data and convert that data into meaningful information and present it in the most engaging way. This could include dashboards , maps and other fun methods.\nThese skills have led me to a very interesting crossroad between traditional epidemiology and newer data science techniques - with endless emerging possibilities.\n\n\n\n\n\n\nNote\n\n\n\nThis website was made using Quarto and the R Programming Language with some additional html and css scripts."
  },
  {
    "objectID": "index.html#primary-care-epidemiology-data-science-data-visualization-geographical-information-systems",
    "href": "index.html#primary-care-epidemiology-data-science-data-visualization-geographical-information-systems",
    "title": "Dr Deepak Varughese, MD",
    "section": "",
    "text": "I am a primary care physician and epidemiologist with experience in rural, tribal and urban settings. I have experience in research design , methodology, data analysis and visualization.\nI believe primary care and family medicine is a powerful piece in the health system. High Quality Primary Care can improve access to care and ensure effective follow up. My areas of clinical interest include chronic disease care, palliative medicine and rehabilitation.\nI believe that my experience in clinical medicine along with skills in epidemiology, biostatistics and programming give me a unique combination of skills to ask relevant questions, collect relevant data and convert that data into meaningful information and present it in the most engaging way. This could include dashboards , maps and other fun methods.\nThese skills have led me to a very interesting crossroad between traditional epidemiology and newer data science techniques - with endless emerging possibilities.\n\n\n\n\n\n\nNote\n\n\n\nThis website was made using Quarto and the R Programming Language with some additional html and css scripts."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "#30DaysMapChallenge",
    "section": "",
    "text": "This is a brief gallery for some Data Visualization ."
  },
  {
    "objectID": "posts.html#day-map-challenge",
    "href": "posts.html#day-map-challenge",
    "title": "#30DaysMapChallenge",
    "section": "",
    "text": "This is a quick page to display all the maps I made as part of #30DayMapChallenge in November 2023. This is a challenge across the mapping community as a way to display better mapping practices. Through this I hope to bring together my love for GIS and Data Viz in order to create better and more compelling visualizations."
  },
  {
    "objectID": "posts/Mallapally Basic Map.html",
    "href": "posts/Mallapally Basic Map.html",
    "title": "A simple map of Mallapally Sub-District",
    "section": "",
    "text": "In this first post on Maps we look to create a very simple map using R Programming.\nFor this project i used R (as usually) and worked with various libraries including ggplot and sf predominantly. I used the Overpass API at https://overpass-turbo.eu/ to collect the shapefiles. (A shapefile is a GIS file that contains various points and polygons for a given areas. ) A lot of the polygons are crowdsourced from the OpenStreetMaps (OSM) community. I used the sf package to open the shapefiles and plot them. I used ggplot2 to create the charts. A lot of the text formatting was done using the showtext package to handle fonts.\n\nThe map is a bit busy. While I would ideally consider making it an interactive map using leaflet I wanted to maintain today’s challenge as a chart. The labels look a bit crowded but i felt the purpose of the chart was labelling today so I kept that as is. I also highlighted the Mallapally Town in the map. I referenced the color by using the same color brown in the description so that it would act as a key of sorts. I have also stuck to good basics by adding a North Arrow and a Scale. This was added using the ggspatial package.\nThis was part one of this series. I hope to build on this chart in future."
  },
  {
    "objectID": "posts/Kerala Population.html",
    "href": "posts/Kerala Population.html",
    "title": "The Population of Kerala",
    "section": "",
    "text": "In the second map of this series i decided to take on a very simple chloropleth map that shows the distribution of population in the South Indian State of Kerala. A chloropleth map often shows different geographic regions that have been shaded according to particular variable.\nFor this map we obtained the administrative borders using overpass from OSM and downloaded the adm_5 layer as adm_5 usually shows the map at the level of district. We then obtained the 2011 Census Data. Yes, this is old census data - but it was the last census that was done. We will assume that overall trends in population may still be the same.\nWe then used different functions on dplyr and stringR to clean the data and finally performed a left_join to merge the population data into the shapefile.\nWe then used ggplot2 for the plotting. We experimented a little with fonts and settled on an informal handwritten type font from the googlefonts collection. The colors were handled by RColorBrewer and i picked a green palate to correlate with the lush vegetation present in Kerala. I avoided the temptation to label each and everything and focused on a simple question of “Which is the district with the highest population”. This allowed me to keep the map more clean and stick to communicating a single message.\nThis was also an exercise in speed as I tried to complete it in limited time rather than focus on the details for too long. Overall a good experience. Hope to keep this going."
  },
  {
    "objectID": "posts2.html",
    "href": "posts2.html",
    "title": "Epidemiology",
    "section": "",
    "text": "This is a quick page to display blogs and teaching resources regarding Epidemiology, Research Methods and Data Science."
  },
  {
    "objectID": "posts2.html#epidemiology",
    "href": "posts2.html#epidemiology",
    "title": "Epidemiology",
    "section": "",
    "text": "This is a quick page to display blogs and teaching resources regarding Epidemiology, Research Methods and Data Science."
  },
  {
    "objectID": "posts2/Why Biostatistics.html#epidemiology",
    "href": "posts2/Why Biostatistics.html#epidemiology",
    "title": "What is Evidence Based Medicine",
    "section": "Epidemiology",
    "text": "Epidemiology\n” The study of the distribution and determinants of health related states or events in specified populations and the applications of this disease to control health problems”"
  },
  {
    "objectID": "posts2/Why Biostatistics.html#objectives-of-epidemiology",
    "href": "posts2/Why Biostatistics.html#objectives-of-epidemiology",
    "title": "What is Evidence Based Medicine",
    "section": "Objectives of Epidemiology",
    "text": "Objectives of Epidemiology\n\nIdentifying risk factors and etiology of disease\nDetermine extent(Burden) of disease in the community\nTo study the Natural History and Prognosis of Disease\nEvaluation of existing and newly developed preventive and therapeutic measures\nProvide a foundation for the development of Health Policy"
  },
  {
    "objectID": "posts2/Why Biostatistics.html#statistics",
    "href": "posts2/Why Biostatistics.html#statistics",
    "title": "What is Evidence Based Medicine",
    "section": "Statistics",
    "text": "Statistics\nField of Study concerned with\n\ncollection, organization, summarization and analysis of data (Descriptive Statistics)\ndrawing of inferences about the data when only a part of the data is observed (Inferential Statistics)"
  },
  {
    "objectID": "posts2/Why Biostatistics.html#data-science",
    "href": "posts2/Why Biostatistics.html#data-science",
    "title": "What is Evidence Based Medicine",
    "section": "Data Science",
    "text": "Data Science"
  },
  {
    "objectID": "posts2/Why Biostatistics.html#evidence-based-medicine",
    "href": "posts2/Why Biostatistics.html#evidence-based-medicine",
    "title": "What is Evidence Based Medicine? Why Study Research Methods?",
    "section": "Evidence Based Medicine",
    "text": "Evidence Based Medicine\nEvidence-based medicine (EBM) uses the scientific method to organize and apply current data to improve healthcare decisions. Thus, the best available science is combined with the healthcare professional’s clinical experience and the patient’s values to arrive at the best medical decision for the patient. \n\nSackett described Evidence Based Medicine as ” the conscienctious, explicit and judicial use of current best evidence in making decisions about the care of the patient. ”\nNote how by this definition EBM does not mean throwing common sense of the clinician out of the window. EBM values Clinical Expertise. It values Patient Values. Yet , it is rooted in science and all decisions need to be backed by solid research data.\nSo why should medical students and those in health care choose to learn good research methods? Is it only to publish papers or do research? Not necessarily. All Health Care Workers may not be very interested in carrying out research but ALL will be consumers of research. Understanding good research methods helps us to critically evaluate “research findings” that are presented to us. According to the EBM model evaluating the best available research is not optional but necessary to be better at health care."
  },
  {
    "objectID": "posts2/Why Biostatistics.html",
    "href": "posts2/Why Biostatistics.html",
    "title": "What is Evidence Based Medicine? Why Study Research Methods?",
    "section": "",
    "text": "In this post we look at what epidemiology is and how it is of value to the health system. I also try to make am argument as to why a thorough knowledge of biostatistics and research methods actually helps us practice better medicine.\nModern Medicine is Evidence Based Medicine. Medical Practitioners have used research data to critically evaluate the best way forward. Best practices change with time depending on new evidence. Yet EBM is not ONLY about data. It is equally about clinical experience as well as Patient Values and Expectations."
  },
  {
    "objectID": "posts2/EBM.html",
    "href": "posts2/EBM.html",
    "title": "What is Evidence Based Medicine? Why Study Research Methods?",
    "section": "",
    "text": "Modern Medicine is Evidence Based Medicine. Medical Practitioners have used research data to critically evaluate the best way forward. Best practices change with time depending on new evidence. Yet EBM is not ONLY about data. It is equally about clinical experience as well as Patient Values and Expectations."
  },
  {
    "objectID": "posts2/EBM.html#evidence-based-medicine",
    "href": "posts2/EBM.html#evidence-based-medicine",
    "title": "What is Evidence Based Medicine? Why Study Research Methods?",
    "section": "Evidence Based Medicine",
    "text": "Evidence Based Medicine\nEvidence-based medicine (EBM) uses the scientific method to organize and apply current data to improve healthcare decisions. Thus, the best available science is combined with the healthcare professional’s clinical experience and the patient’s values to arrive at the best medical decision for the patient. \n\nSackett described Evidence Based Medicine as ” the conscienctious, explicit and judicial use of current best evidence in making decisions about the care of the patient. ”\nNote how by this definition EBM does not mean throwing common sense of the clinician out of the window. EBM values Clinical Expertise. It values Patient Values. Yet , it is rooted in science and all decisions need to be backed by solid research data."
  },
  {
    "objectID": "posts2/EBM.html#why-study-research-methods",
    "href": "posts2/EBM.html#why-study-research-methods",
    "title": "What is Evidence Based Medicine? Why Study Research Methods?",
    "section": "Why Study Research Methods?",
    "text": "Why Study Research Methods?\nSo why should medical students and those in health care choose to learn good research methods? Is it only to publish papers or do research? Not necessarily. All Health Care Workers may not be very interested in carrying out research but ALL will be consumers of research. Understanding good research methods helps us to critically evaluate “research findings” that are presented to us. According to the EBM model evaluating the best available research is not optional but necessary to be better at health care."
  },
  {
    "objectID": "posts2/What_is_Stats.html#biostatistics",
    "href": "posts2/What_is_Stats.html#biostatistics",
    "title": "What is BioStatistics",
    "section": "",
    "text": "Why should those of us working in the health system have an idea of Biostatistics? Does it really matter?\nIn a previous post we looked at what Evidence Based Medicine was. We looked at the work of David Sackett and how he defined EBM as having 3 components - Availability of Best External Evidence, Clinical Experience and Patient Values.\nNotice that one of the components is referring to the best external evidence. Is this necessary? Ofcourse yes. In healthcare we want to do the best for our patients and our communities - and basing our decisions on sound foundations is crucial. This means that all healthcare workers should have an understanding of how to read and evaluate evidence - even if they are not actively generating new evidence via research. Not all of us may create new evidence but all of us will be consumers of research.\nSo what is Biostatistics even?\nA formal definition of Biostatistics would be :\nA Field of Study concerned with\n\ncollection, organization, summarization and analysis of data (Descriptive Statistics)\ndrawing of inferences about the data when only a part of the data is observed (Inferential Statistics)\n\nSimply put we can put the biostatistics in two broad headings.\nIf we were to describe a particular phenomenon - for example - number of days a patient spends in a hospital - it would be pointless to list out all the individual durations of hospital stay. We would need to pick one or two numbers that could best describe and communicate this. We often use measures of central tendency to give a sense of what the most common value is (such as mean, median etc) to do this. We often also use other measures to give a sense of how spread out the data is (such as standard deviation or interquartile range). A solid understanding of which measure to use when - and selecting the most appropriate measure maybe far more important as compared to simply doing the math.\nAnother very important use case of statistics is to make inferences. Most people in my limited sample had an admission duration of 5 days - but can i now infer what the average duration of admission is in my entire state? Will it vary? Can i give a range of expected duration of admission? How many days will i likely to be admitted if i were to need to be admitted? These questions are likely to be answered using Inferential Statistics. Calculation of a Population Mean, Standard Errors, Confidence Intervals, Regression etc are some terms you may have heard that relate closely with inferential statistics."
  },
  {
    "objectID": "posts2/What_is_Stats.html#data-science",
    "href": "posts2/What_is_Stats.html#data-science",
    "title": "What is BioStatistics",
    "section": "Data Science",
    "text": "Data Science\n\nAnother closely related topic is Data Science. Data Science revolves around a statistics, good domain knowledge (really understanding the field) and good programming knowledge. A solid foundation in statistics is foundational for Data Science. Traditional Biostatistics also requires an understanding of domain knowledge. Data Science however places a much more heavier focus on programming skills in comparison to traditional biostatistics. There is also a more strong focus on dealing with secondary data (that has been collected for other reasons) while traditional biostatistics has usually preferred to deal with primary data( that has been collected specifically for this purpose.) Data Scientists also typically deal with tasks such as Machine Learning and Product Development when compared to traditional biostatistics. That is not to say that the skills are not transferrable. There is certainly a lot of overlap. Some of the biggest names in the Data Science Community have come from the world of biostatistics. In fact a solid foundation in statistics can be foundational in building a strong data science profile."
  },
  {
    "objectID": "posts2/What_is_Stats.html",
    "href": "posts2/What_is_Stats.html",
    "title": "What is BioStatistics",
    "section": "",
    "text": "Why should those of us working in the health system have an idea of Biostatistics? Does it really matter?\nIn a previous post we looked at what Evidence Based Medicine was. We looked at the work of David Sackett and how he defined EBM as having 3 components - Availability of Best External Evidence, Clinical Experience and Patient Values.\nNotice that one of the components is referring to the best external evidence. Is this necessary? Ofcourse yes. In healthcare we want to do the best for our patients and our communities - and basing our decisions on sound foundations is crucial. This means that all healthcare workers should have an understanding of how to read and evaluate evidence - even if they are not actively generating new evidence via research. Not all of us may create new evidence but all of us will be consumers of research.\nSo what is Biostatistics even?\nA formal definition of Biostatistics would be :\nA Field of Study concerned with\n\ncollection, organization, summarization and analysis of data (Descriptive Statistics)\ndrawing of inferences about the data when only a part of the data is observed (Inferential Statistics)\n\nSimply put we can put the biostatistics in two broad headings.\nIf we were to describe a particular phenomenon - for example - number of days a patient spends in a hospital - it would be pointless to list out all the individual durations of hospital stay. We would need to pick one or two numbers that could best describe and communicate this. We often use measures of central tendency to give a sense of what the most common value is (such as mean, median etc) to do this. We often also use other measures to give a sense of how spread out the data is (such as standard deviation or interquartile range). A solid understanding of which measure to use when - and selecting the most appropriate measure maybe far more important as compared to simply doing the math.\nAnother very important use case of statistics is to make inferences. Most people in my limited sample had an admission duration of 5 days - but can i now infer what the average duration of admission is in my entire state? Will it vary? Can i give a range of expected duration of admission? How many days will i likely to be admitted if i were to need to be admitted? These questions are likely to be answered using Inferential Statistics. Calculation of a Population Mean, Standard Errors, Confidence Intervals, Regression etc are some terms you may have heard that relate closely with inferential statistics."
  },
  {
    "objectID": "posts3.html",
    "href": "posts3.html",
    "title": "R Training Material",
    "section": "",
    "text": "This page has slides for R Training."
  },
  {
    "objectID": "posts3.html#general-practice-and-family-medicine",
    "href": "posts3.html#general-practice-and-family-medicine",
    "title": "General Practice and Family Medicine",
    "section": "",
    "text": "This is a page where we will discuss management of common diseases from a General Practice point of view in the Indian Context."
  },
  {
    "objectID": "posts3.html#r-training-material",
    "href": "posts3.html#r-training-material",
    "title": "R Training Material",
    "section": "",
    "text": "This page has slides for R Training."
  },
  {
    "objectID": "What is R.html#how-do-computers-work",
    "href": "What is R.html#how-do-computers-work",
    "title": "An Introduction to Programming and R for Academics",
    "section": "How do computers work ?",
    "text": "How do computers work ?\n\nComputers are made up of billions of transistors that can either be in a state of being open or closed. They decide on whether to be open or closed depending on a series of commands that are written as 0 and 1.\n\nA series of 0s and 1s often tell the computer what to do.\n\nFor example\n0000110000000001000011010000000100000010000011000001101\nThis may possibly be a series of binary code that can tell the computer to add 1+1."
  },
  {
    "objectID": "What is R.html#talking-to-a-computer.-what-happens-behind-the-scenes.",
    "href": "What is R.html#talking-to-a-computer.-what-happens-behind-the-scenes.",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Talking to a computer. What happens behind the scenes.",
    "text": "Talking to a computer. What happens behind the scenes.\nA high-level programming language is usually used by a developer to tell the computer what to do.\n\nHigh-Level Programming languages are written in English but still need to follow a particular syntax. These are relatively easier to write.\n\nA High Level Programming language is converted to a what is called assembly code by a compiler. Assembly code is usually never written directly since it depends on the type of processor one is using.\n\nThe assembly code is then assembled to binary code by an assembler. This is a series of 1s and 0s.\n\nBinary code is then converted to electric signals which are used by the processor to do the actual computing."
  },
  {
    "objectID": "What is R.html#i-dont-write-any-code.-why-does-this-matter-to-me",
    "href": "What is R.html#i-dont-write-any-code.-why-does-this-matter-to-me",
    "title": "An Introduction to Programming and R for Academics",
    "section": "I don’t write any code. Why does this matter to me?",
    "text": "I don’t write any code. Why does this matter to me?\nMost users use Graphic User Interfaces (GUIs) to interact with the computer. (This is FINE)\n\nGUIs are about visual elements like Icons, Windows , Menus and Buttons. GUIs allow the user to use a mouse to point and click to execute functions that run at the backend without the user having to worry about it.\n\nThe GUIs are themselves written in a high-level programming language like Java , C++ , Python or R.\nFor example - Microsoft Excel or SPSS is written in a combination of languages like C++, Java and FORTRAN . So everytime a button is clicked a function in that respective language is executed at the backend without the user having to worry about it."
  },
  {
    "objectID": "What is R.html#what-is-r",
    "href": "What is R.html#what-is-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "What is R",
    "text": "What is R\nR is a high level programming language\nBuilt with a focus on\n\nStatistics\nData Visualizations\n\nIt has hence grown to have many other applications\n\n\nInteractive App Development\nAI and Machine Learning\nPresentations (This presentation is written in R!)\nReports\nWebsite Development"
  },
  {
    "objectID": "What is R.html#website-made-in-r",
    "href": "What is R.html#website-made-in-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Website made in R ",
    "text": "Website made in R"
  },
  {
    "objectID": "What is R.html#dashboard-made-in-r",
    "href": "What is R.html#dashboard-made-in-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Dashboard made in R ",
    "text": "Dashboard made in R"
  },
  {
    "objectID": "What is R.html#presentation-made-in-r",
    "href": "What is R.html#presentation-made-in-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Presentation made in R",
    "text": "Presentation made in R\n\n(This presentation is made in R !)"
  },
  {
    "objectID": "What is R.html#visualizations-made-in-r",
    "href": "What is R.html#visualizations-made-in-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Visualizations made in R",
    "text": "Visualizations made in R\n\nSource : https://www.tanyashapiro.com/gallery?itemId=pj2874o8w5jtncinvwp665lxr78hkp-htnaf-gyhmhhttps://www.tanyashapiro.com/gallery?itemId=pj2874o8w5jtncinvwp665lxr78hkp-htnaf-gyhmh"
  },
  {
    "objectID": "What is R.html#maps-using-r",
    "href": "What is R.html#maps-using-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Maps Using R",
    "text": "Maps Using R"
  },
  {
    "objectID": "What is R.html#advantages-of-using-r",
    "href": "What is R.html#advantages-of-using-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Advantages of Using R",
    "text": "Advantages of Using R\n\nFree\nOpen Source\nReproducible\nVery Flexible (Talk DIRECTLY to the computer without a GUI)\nVery Powerful"
  },
  {
    "objectID": "What is R.html#barriers-to-using-r",
    "href": "What is R.html#barriers-to-using-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Barriers to Using R",
    "text": "Barriers to Using R\n\nSteep-Learning Curve with Mental Blocks ( CAN BE OVERCOME)"
  },
  {
    "objectID": "What is R.html#other-considerations",
    "href": "What is R.html#other-considerations",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Other Considerations",
    "text": "Other Considerations\nHave Lots of Funding?\n\n\nSPSS / STATA for Analysis\nArcGIS for Mapping\nHire a Web-Developer and Outsource work"
  },
  {
    "objectID": "What is R.html#other-considerations-1",
    "href": "What is R.html#other-considerations-1",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Other Considerations",
    "text": "Other Considerations\nWant a Graphical User Interface ?\n\nPaid Tools as above\nMicrosoft Office (Excel , Powerpoint)\nGoogle Sheets , Google Slides\nFree Tools\n\nOnly for Statistics - Consider JAMOVI (Which is a GUI for easy access to R)\nOnly for Mapping - Consider QGIS\nOnly for Visualization - Consider Canva for basic visualization that is not data-intensive."
  },
  {
    "objectID": "What is R.html#want-free-flexible-reproducible-possibility-of-automation",
    "href": "What is R.html#want-free-flexible-reproducible-possibility-of-automation",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Want Free , Flexible, Reproducible, Possibility of Automation?",
    "text": "Want Free , Flexible, Reproducible, Possibility of Automation?\n\nConsider R (or Python)\n\nR / Julia\n\nif working in academia , statistics\n\nPython\n\nIf working in web-development , more general purpose coding"
  },
  {
    "objectID": "What is R.html#want-to-go-one-step-further",
    "href": "What is R.html#want-to-go-one-step-further",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Want to go one step further ?",
    "text": "Want to go one step further ?\nConsider combining R for statistics, Python for Web Development and SQL for Database Management.\n\nLearning your first language is the hardest! Get a grasp of one language it becomes easier to pivot to other languages."
  },
  {
    "objectID": "What is R.html#takehome-messages",
    "href": "What is R.html#takehome-messages",
    "title": "An Introduction to Programming and R for Academics",
    "section": "TAKEHOME MESSAGES",
    "text": "TAKEHOME MESSAGES\n\nPick your tool for the job you want to do.\nUse a combination of tools if the need be.\nR is a language , not a straight replacement for STATA or SPSS.\nIt offers flexibility, reproducibility, open source and possibilty to automate\nIT CAN BE LEARNT. WE WILL DO THIS"
  },
  {
    "objectID": "posts3/What is R.html#how-do-computers-work",
    "href": "posts3/What is R.html#how-do-computers-work",
    "title": "An Introduction to Programming and R for Academics",
    "section": "How do computers work ?",
    "text": "How do computers work ?\n\nComputers are made up of billions of transistors that can either be in a state of being open or closed. They decide on whether to be open or closed depending on a series of commands that are written as 0 and 1.\n\nA series of 0s and 1s often tell the computer what to do.\n\nFor example\n0000110000000001000011010000000100000010000011000001101\nThis may possibly be a series of binary code that can tell the computer to add 1+1."
  },
  {
    "objectID": "posts3/What is R.html#talking-to-a-computer.-what-happens-behind-the-scenes.",
    "href": "posts3/What is R.html#talking-to-a-computer.-what-happens-behind-the-scenes.",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Talking to a computer. What happens behind the scenes.",
    "text": "Talking to a computer. What happens behind the scenes.\nA high-level programming language is usually used by a developer to tell the computer what to do.\n\nHigh-Level Programming languages are written in English but still need to follow a particular syntax. These are relatively easier to write.\n\nA High Level Programming language is converted to a what is called assembly code by a compiler. Assembly code is usually never written directly since it depends on the type of processor one is using.\n\nThe assembly code is then assembled to binary code by an assembler. This is a series of 1s and 0s.\n\nBinary code is then converted to electric signals which are used by the processor to do the actual computing."
  },
  {
    "objectID": "posts3/What is R.html#i-dont-write-any-code.-why-does-this-matter-to-me",
    "href": "posts3/What is R.html#i-dont-write-any-code.-why-does-this-matter-to-me",
    "title": "An Introduction to Programming and R for Academics",
    "section": "I don’t write any code. Why does this matter to me?",
    "text": "I don’t write any code. Why does this matter to me?\nMost users use Graphic User Interfaces (GUIs) to interact with the computer. (This is FINE)\n\nGUIs are about visual elements like Icons, Windows , Menus and Buttons. GUIs allow the user to use a mouse to point and click to execute functions that run at the backend without the user having to worry about it.\n\nThe GUIs are themselves written in a high-level programming language like Java , C++ , Python or R.\nFor example - Microsoft Excel or SPSS is written in a combination of languages like C++, Java and FORTRAN . So everytime a button is clicked a function in that respective language is executed at the backend without the user having to worry about it."
  },
  {
    "objectID": "posts3/What is R.html#what-is-r",
    "href": "posts3/What is R.html#what-is-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "What is R",
    "text": "What is R\nR is a high level programming language\nBuilt with a focus on\n\nStatistics\nData Visualizations\n\nIt has hence grown to have many other applications\n\n\nInteractive App Development\nAI and Machine Learning\nPresentations (This presentation is written in R!)\nReports\nWebsite Development"
  },
  {
    "objectID": "posts3/What is R.html#website-made-in-r",
    "href": "posts3/What is R.html#website-made-in-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Website made in R ",
    "text": "Website made in R"
  },
  {
    "objectID": "posts3/What is R.html#dashboard-made-in-r",
    "href": "posts3/What is R.html#dashboard-made-in-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Dashboard made in R ",
    "text": "Dashboard made in R"
  },
  {
    "objectID": "posts3/What is R.html#presentation-made-in-r",
    "href": "posts3/What is R.html#presentation-made-in-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Presentation made in R",
    "text": "Presentation made in R\n\n(This presentation is made in R !)"
  },
  {
    "objectID": "posts3/What is R.html#visualizations-made-in-r",
    "href": "posts3/What is R.html#visualizations-made-in-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Visualizations made in R",
    "text": "Visualizations made in R\n\nSource : https://www.tanyashapiro.com/gallery?itemId=pj2874o8w5jtncinvwp665lxr78hkp-htnaf-gyhmhhttps://www.tanyashapiro.com/gallery?itemId=pj2874o8w5jtncinvwp665lxr78hkp-htnaf-gyhmh"
  },
  {
    "objectID": "posts3/What is R.html#maps-using-r",
    "href": "posts3/What is R.html#maps-using-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Maps Using R",
    "text": "Maps Using R"
  },
  {
    "objectID": "posts3/What is R.html#advantages-of-using-r",
    "href": "posts3/What is R.html#advantages-of-using-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Advantages of Using R",
    "text": "Advantages of Using R\n\nFree\nOpen Source\nReproducible\nVery Flexible (Talk DIRECTLY to the computer without a GUI)\nVery Powerful"
  },
  {
    "objectID": "posts3/What is R.html#barriers-to-using-r",
    "href": "posts3/What is R.html#barriers-to-using-r",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Barriers to Using R",
    "text": "Barriers to Using R\n\nSteep-Learning Curve with Mental Blocks ( CAN BE OVERCOME)"
  },
  {
    "objectID": "posts3/What is R.html#other-considerations",
    "href": "posts3/What is R.html#other-considerations",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Other Considerations",
    "text": "Other Considerations\nHave Lots of Funding?\n\n\nSPSS / STATA for Analysis\nArcGIS for Mapping\nHire a Web-Developer and Outsource work"
  },
  {
    "objectID": "posts3/What is R.html#other-considerations-1",
    "href": "posts3/What is R.html#other-considerations-1",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Other Considerations",
    "text": "Other Considerations\nWant a Graphical User Interface ?\n\nPaid Tools as above\nMicrosoft Office (Excel , Powerpoint)\nGoogle Sheets , Google Slides\nFree Tools\n\nOnly for Statistics - Consider JAMOVI (Which is a GUI for easy access to R)\nOnly for Mapping - Consider QGIS\nOnly for Visualization - Consider Canva for basic visualization that is not data-intensive."
  },
  {
    "objectID": "posts3/What is R.html#want-free-flexible-reproducible-possibility-of-automation",
    "href": "posts3/What is R.html#want-free-flexible-reproducible-possibility-of-automation",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Want Free , Flexible, Reproducible, Possibility of Automation?",
    "text": "Want Free , Flexible, Reproducible, Possibility of Automation?\n\nConsider R (or Python)\n\nR / Julia\n\nif working in academia , statistics\n\nPython\n\nIf working in web-development , more general purpose coding"
  },
  {
    "objectID": "posts3/What is R.html#want-to-go-one-step-further",
    "href": "posts3/What is R.html#want-to-go-one-step-further",
    "title": "An Introduction to Programming and R for Academics",
    "section": "Want to go one step further ?",
    "text": "Want to go one step further ?\nConsider combining R for statistics, Python for Web Development and SQL for Database Management.\n\nLearning your first language is the hardest! Get a grasp of one language it becomes easier to pivot to other languages."
  },
  {
    "objectID": "posts3/What is R.html#takehome-messages",
    "href": "posts3/What is R.html#takehome-messages",
    "title": "An Introduction to Programming and R for Academics",
    "section": "TAKEHOME MESSAGES",
    "text": "TAKEHOME MESSAGES\n\nPick your tool for the job you want to do.\nUse a combination of tools if the need be.\nR is a language , not a straight replacement for STATA or SPSS.\nIt offers flexibility, reproducibility, open source and possibilty to automate\nIT CAN BE LEARNT. WE WILL DO THIS"
  },
  {
    "objectID": "posts3/Installing R on your System.html#can-i-just-download-r-and-run-it",
    "href": "posts3/Installing R on your System.html#can-i-just-download-r-and-run-it",
    "title": "Installing R on your System",
    "section": "Can I just download R and run it?",
    "text": "Can I just download R and run it?\nTechnically Yes - but usually no.\nR is a language that you need to install on your PC\nIt is usually combined with an Integrated Development Environment like RStudio\nThe IDE is used to compile and run the code."
  },
  {
    "objectID": "posts3/Installing R on your System.html#integrated-development-environment",
    "href": "posts3/Installing R on your System.html#integrated-development-environment",
    "title": "Installing R on your System",
    "section": "Integrated Development Environment",
    "text": "Integrated Development Environment\nAn IDE is a tool that complies and runs the code you write. Modern IDEs can also have other features like File Browsing, Code Completion , debugging etc\nThe most commonly used IDE used with R is R Studio (from Posit)"
  },
  {
    "objectID": "posts3/Installing R on your System.html#other-popular-ides",
    "href": "posts3/Installing R on your System.html#other-popular-ides",
    "title": "Installing R on your System",
    "section": "Other Popular IDEs",
    "text": "Other Popular IDEs\nOther IDEs that are gaining popularity include Positron (Also from Posit) and VS Code\nPositron and VS Code can be useful especially if one would like to combine different programming languages like Python and R in the same environment. Since RStudio is the traditional IDE used for R we will use R Studio for these tutorials.\nYou may however choose to use a different IDE and experiment with it if you like."
  },
  {
    "objectID": "posts3/Installing R on your System.html#rstudio",
    "href": "posts3/Installing R on your System.html#rstudio",
    "title": "Installing R on your System",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "posts3/Installing R on your System.html#positron",
    "href": "posts3/Installing R on your System.html#positron",
    "title": "Installing R on your System",
    "section": "Positron",
    "text": "Positron"
  },
  {
    "objectID": "posts3/Installing R on your System.html#hands-on-installing-r",
    "href": "posts3/Installing R on your System.html#hands-on-installing-r",
    "title": "Installing R on your System",
    "section": "Hands-on : Installing R",
    "text": "Hands-on : Installing R\nhttps://posit.co/download/rstudio-desktop/"
  },
  {
    "objectID": "posts3/Installing R on your System.html#hands-on-installing-r-1",
    "href": "posts3/Installing R on your System.html#hands-on-installing-r-1",
    "title": "Installing R on your System",
    "section": "Hands-on : Installing R",
    "text": "Hands-on : Installing R"
  },
  {
    "objectID": "posts3/rstudio_interface.html#the-interface",
    "href": "posts3/rstudio_interface.html#the-interface",
    "title": "The R Studio Interface",
    "section": "The Interface",
    "text": "The Interface"
  },
  {
    "objectID": "posts3/rstudio_interface.html#scripting-window",
    "href": "posts3/rstudio_interface.html#scripting-window",
    "title": "The R Studio Interface",
    "section": "SCRIPTING WINDOW",
    "text": "SCRIPTING WINDOW\nThis is your workhorse. This is where you actually write code.\nCode you write here can be saved as a script and can be used later.\n\nNOTE\nENTER merely goes to the next line in the scripting window.\nIn order to run the code you need to highlight the code you want to run and click Cntrl+Enter (Or use the mouse to click “run”."
  },
  {
    "objectID": "posts3/rstudio_interface.html#environment",
    "href": "posts3/rstudio_interface.html#environment",
    "title": "The R Studio Interface",
    "section": "ENVIRONMENT",
    "text": "ENVIRONMENT\nAll the datasets and variables you load into R can be found from the Environment Tab. We will discuss this in length further. For now remember that you can see your datasets and variables inside this window."
  },
  {
    "objectID": "posts3/rstudio_interface.html#files",
    "href": "posts3/rstudio_interface.html#files",
    "title": "The R Studio Interface",
    "section": "FILES",
    "text": "FILES\nThis window can be toggled to show you the different files available on your PC similar to a browser. You can also view any plots or figures in this tab."
  },
  {
    "objectID": "posts3/rstudio_interface.html#console",
    "href": "posts3/rstudio_interface.html#console",
    "title": "The R Studio Interface",
    "section": "CONSOLE",
    "text": "CONSOLE\nFor the beginner level just be aware that code you run is displayed in the console. Many outputs, errors etc can be seen in the console panel. We do NOT normally type inside the console on a day to day basis. There are a few use cases where one would type into the console but this is not the normal. Usually typing is done in the scripting window and not the console. More advanced users may also access the terminal from this window. We will look at this in further modules."
  },
  {
    "objectID": "posts3/Setting Up R Studio.html#changing-the-options",
    "href": "posts3/Setting Up R Studio.html#changing-the-options",
    "title": "Initial Setup of RStudio",
    "section": "Changing the options",
    "text": "Changing the options"
  },
  {
    "objectID": "posts3/Setting Up R Studio.html#unchecking-boxes",
    "href": "posts3/Setting Up R Studio.html#unchecking-boxes",
    "title": "Initial Setup of RStudio",
    "section": "Unchecking boxes",
    "text": "Unchecking boxes\nPlease ensure that the following boxes are unticked\n\nRestore most recently opened project at Startup\nRestore Previously Open Source Documents at Startup\nRestore .RData into Workspace on Startup"
  },
  {
    "objectID": "posts3/staying_organized_with_projects.html#why-use-projects",
    "href": "posts3/staying_organized_with_projects.html#why-use-projects",
    "title": "Getting Organized with Projects",
    "section": "Why use Projects?",
    "text": "Why use Projects?\nOne of the challenges in any project especially with data is staying organized.\nManuscripts, Datasets, Images etc are all usually saved in multiple locations slowing down efficiency in a big way.\nR Projects is a neat way to force one to remain organized.\nWorking with projects improves the ease of use of R signinificantly and is HIGHLY RECOMMENDED.\nFor the purpose of this course we will be using projects and highly recommend you do the same for all your projects."
  },
  {
    "objectID": "posts3/staying_organized_with_projects.html#how-to-create-a-project",
    "href": "posts3/staying_organized_with_projects.html#how-to-create-a-project",
    "title": "Getting Organized with Projects",
    "section": "How to create a project",
    "text": "How to create a project"
  },
  {
    "objectID": "posts3/staying_organized_with_projects.html#new-project",
    "href": "posts3/staying_organized_with_projects.html#new-project",
    "title": "Getting Organized with Projects",
    "section": "New Project",
    "text": "New Project"
  },
  {
    "objectID": "posts3/staying_organized_with_projects.html#project-options",
    "href": "posts3/staying_organized_with_projects.html#project-options",
    "title": "Getting Organized with Projects",
    "section": "Project Options",
    "text": "Project Options"
  },
  {
    "objectID": "posts3/rstudio_interface.html#exercise",
    "href": "posts3/rstudio_interface.html#exercise",
    "title": "The R Studio Interface",
    "section": "Exercise",
    "text": "Exercise\n\nInstall R and then identify all the panels correctly."
  },
  {
    "objectID": "posts4.html",
    "href": "posts4.html",
    "title": "GIS Training Material",
    "section": "",
    "text": "This page has slides for GIS."
  },
  {
    "objectID": "posts4.html#gis-training-material",
    "href": "posts4.html#gis-training-material",
    "title": "GIS Training Material",
    "section": "",
    "text": "This page has slides for GIS."
  },
  {
    "objectID": "posts4/intro_to_gis.html#epidemiology",
    "href": "posts4/intro_to_gis.html#epidemiology",
    "title": "Intro to GIS for Public Health",
    "section": "",
    "text": "The study of the distribution of Disease and Disease Related States\n\nBy Person\nBy Place\nBy Time"
  },
  {
    "objectID": "posts4/intro_to_gis.html#by-person",
    "href": "posts4/intro_to_gis.html#by-person",
    "title": "Intro to GIS for Public Health",
    "section": "By Person",
    "text": "By Person\nWho is likely to get the disease? What are the risk factors\n\nCase Control Studies\nCohort Studies\nRandomized Control Trials\nQuasi-Experimental Designs"
  },
  {
    "objectID": "posts4/intro_to_gis.html#by-time",
    "href": "posts4/intro_to_gis.html#by-time",
    "title": "Intro to GIS for Public Health",
    "section": "By Time",
    "text": "By Time\nHow is the disease changing over time?\n\nTime Series Analysis\nCohort Studies\nRepeated Cross Sectional Studies"
  },
  {
    "objectID": "posts4/intro_to_gis.html#by-place",
    "href": "posts4/intro_to_gis.html#by-place",
    "title": "Intro to GIS for Public Health",
    "section": "By Place",
    "text": "By Place\n\nEcological Studies\nCase Control Studies\nDifference in Difference Designs"
  },
  {
    "objectID": "posts4/intro_to_gis.html#who-where-when",
    "href": "posts4/intro_to_gis.html#who-where-when",
    "title": "Intro to GIS for Public Health",
    "section": "Who? Where? When?",
    "text": "Who? Where? When?\nGIS Provides the “where” in the traditional “who, where, when triad” in epidemiology\nIt can also be clubbed with the when - to provide “Spatio-Temporal” Insights."
  },
  {
    "objectID": "posts4/intro_to_gis.html#gis",
    "href": "posts4/intro_to_gis.html#gis",
    "title": "Intro to GIS for Public Health",
    "section": "GIS",
    "text": "GIS\n\nGeographical Information Systems\nGeospatial Information Systems\nSpatial Data Science"
  },
  {
    "objectID": "posts4/intro_to_gis.html#is-mapping-in-public-health-new",
    "href": "posts4/intro_to_gis.html#is-mapping-in-public-health-new",
    "title": "Intro to GIS for Public Health",
    "section": "Is Mapping in Public Health New?",
    "text": "Is Mapping in Public Health New?"
  },
  {
    "objectID": "posts4/intro_to_gis.html#advantages-of-hand--drawn-paper-maps",
    "href": "posts4/intro_to_gis.html#advantages-of-hand--drawn-paper-maps",
    "title": "Intro to GIS for Public Health",
    "section": "Advantages of Hand- Drawn Paper Maps?",
    "text": "Advantages of Hand- Drawn Paper Maps?\n\nLocal Knowledge?\n\n\n\n“The Map is not the territory” - In-Depth knowledge of intricacies that may not be captured on the map.\nAccessibility - Do not need special training or tools\n“Fail Safe” - Do not depend on technology / power requirements etc"
  },
  {
    "objectID": "posts4/intro_to_gis.html#disadvantages-of-hand-drawn-paper-maps",
    "href": "posts4/intro_to_gis.html#disadvantages-of-hand-drawn-paper-maps",
    "title": "Intro to GIS for Public Health",
    "section": "Disadvantages of Hand Drawn Paper Maps",
    "text": "Disadvantages of Hand Drawn Paper Maps\n\nNot to scale?\nPrecision in distance , etc\nDifficult to stack maps on top of each other\nStatic and Difficult to Update\nLimited by size and scale"
  },
  {
    "objectID": "posts4/intro_to_gis.html#so-what-then-is-gis-anyway-is-it-just-a-digital-map",
    "href": "posts4/intro_to_gis.html#so-what-then-is-gis-anyway-is-it-just-a-digital-map",
    "title": "Intro to GIS for Public Health",
    "section": "So what then is GIS anyway? Is it just a digital map?",
    "text": "So what then is GIS anyway? Is it just a digital map?\nA GIS system has 2 main components\n\nA geography or shape (eg - Points, Polygons, Boundaries, Rasters) - WHERE\nA table storing information - WHAT"
  },
  {
    "objectID": "posts4/intro_to_gis.html#section",
    "href": "posts4/intro_to_gis.html#section",
    "title": "Intro to GIS for Public Health",
    "section": "",
    "text": "A GIS system has 2 main components\n\nA geography or shape (eg - Points, Polygons, Boundaries, Rasters) - WHERE\nA table storing information - WHAT"
  },
  {
    "objectID": "posts4/intro_to_gis.html#gis-vs-static-maps",
    "href": "posts4/intro_to_gis.html#gis-vs-static-maps",
    "title": "Intro to GIS for Public Health",
    "section": "GIS vs Static Maps",
    "text": "GIS vs Static Maps\nCreating Maps is one of the many possibilities of GIS\nGIS is not about simply displaying static information but allowing the users to ask questions of the data\n\nWhat is the shortest distance from Point A to Point B\nWhat is an ideal catchment area for my services\nHow is the distribution of air-pollution related to the distribution of COPD"
  },
  {
    "objectID": "posts4/intro_to_gis.html#tools-used-for-gis",
    "href": "posts4/intro_to_gis.html#tools-used-for-gis",
    "title": "Intro to GIS for Public Health",
    "section": "Tools used for GIS",
    "text": "Tools used for GIS\nA wide combination of software solutions can be used for GIS related work.\n\nArcGIS - Commercial , Proprietary - Licences are approximately (Prices could vary from USD100 to USD3800 per Year depending on licence types)\nQGIS - Free and Open Source.\n\nOther Useful Programming Languages handy for GIS\n\nPython\nR\nSQL / PostGIS"
  },
  {
    "objectID": "posts4/intro_to_gis.html#types-of-data-in-gis",
    "href": "posts4/intro_to_gis.html#types-of-data-in-gis",
    "title": "Intro to GIS for Public Health",
    "section": "Types of Data in GIS",
    "text": "Types of Data in GIS\n\nVector Data\n\nPoints\nLines\nPolygons\n\nRaster Data\n\nA type of Digital photograph that represents Continuous Data where values change gradually over space\n\nPopulation\nElevation\nLand Use / Land Cover\nTemperature"
  },
  {
    "objectID": "posts3/General Syntax in R.html#functions-in-r",
    "href": "posts3/General Syntax in R.html#functions-in-r",
    "title": "Basic Syntax in R",
    "section": "Functions in R",
    "text": "Functions in R\nFictional function from the Epi R Handbook\n\nSource : https://www.epirhandbook.com/en/new_pages/basics.html"
  },
  {
    "objectID": "posts3/General Syntax in R.html#functions",
    "href": "posts3/General Syntax in R.html#functions",
    "title": "Basic Syntax in R",
    "section": "Functions",
    "text": "Functions\n\nSource : https://www.epirhandbook.com/en/new_pages/basics.html"
  },
  {
    "objectID": "posts3/General Syntax in R.html#where-do-functions-come-from",
    "href": "posts3/General Syntax in R.html#where-do-functions-come-from",
    "title": "Basic Syntax in R",
    "section": "Where do Functions come from?",
    "text": "Where do Functions come from?\nFunctions can belong to either base R or to packages.\n\nIf you want to specify which package to call a function\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "posts3/Introduction to the tidyverse.html#origin-story",
    "href": "posts3/Introduction to the tidyverse.html#origin-story",
    "title": "An Introduction to the tidyverse",
    "section": "Origin Story",
    "text": "Origin Story\n\n\n\n\n\n\nOrigin\n\n\n“The hardest part of collaborative data analysis is not finding the correct statistical model, but getting the data into a form that you can actually work with. This challenge led to the creation of the reshape package which made it easier to work with a variety of input datasets by first converting to a “molten” form which you could then “cast” into the desired form.”\n\nHadley Wickham\n\n\n\n\nhttps://hadley.github.io/25-tidyverse-history/?trk=feed_main-feed-card_feed-article-content"
  },
  {
    "objectID": "posts3/Introduction to the tidyverse.html#the-data-science-process",
    "href": "posts3/Introduction to the tidyverse.html#the-data-science-process",
    "title": "An Introduction to the tidyverse",
    "section": "The Data Science Process",
    "text": "The Data Science Process\n\nhttps://hadley.github.io/25-tidyverse-history/?trk=feed_main-feed-card_feed-article-content"
  },
  {
    "objectID": "posts3/Introduction to the tidyverse.html#principles-of-tidy-data",
    "href": "posts3/Introduction to the tidyverse.html#principles-of-tidy-data",
    "title": "An Introduction to the tidyverse",
    "section": "Principles of Tidy Data",
    "text": "Principles of Tidy Data\n\nEach variable must have its own column\nEach observation must have its own row\nEach value must have its own cell\n\n\nSource : https://r4ds.had.co.nz/tidy-data.html"
  },
  {
    "objectID": "posts3/Introduction to the tidyverse.html#number-of-cases-of-fictional-disease-in-the-us-and-india",
    "href": "posts3/Introduction to the tidyverse.html#number-of-cases-of-fictional-disease-in-the-us-and-india",
    "title": "An Introduction to the tidyverse",
    "section": "Number of Cases of Fictional Disease in the US and India",
    "text": "Number of Cases of Fictional Disease in the US and India\n\n\n\nCountry\n2023\n2024\n2025\n\n\n\n\nIndia\n600\n400\n500\n\n\nUS\n500\n200\n400"
  },
  {
    "objectID": "posts3/Introduction to the tidyverse.html#number-of-cases-of-fictional-disease-in-the-us-and-india-1",
    "href": "posts3/Introduction to the tidyverse.html#number-of-cases-of-fictional-disease-in-the-us-and-india-1",
    "title": "An Introduction to the tidyverse",
    "section": "Number of Cases of Fictional Disease in the US and India",
    "text": "Number of Cases of Fictional Disease in the US and India\n\n\n\nCountry\nYear\nNumber of Cases\n\n\n\n\nIndia\n2023\n600\n\n\nIndia\n2024\n400\n\n\nIndia\n2025\n500\n\n\nUS\n2023\n500\n\n\nUS\n2024\n200\n\n\nUS\n2025\n400\n\n\n\nLong Format vs Wide Format"
  },
  {
    "objectID": "posts3/Introduction to the tidyverse.html#what-is-the-tidyverse",
    "href": "posts3/Introduction to the tidyverse.html#what-is-the-tidyverse",
    "title": "An Introduction to the tidyverse",
    "section": "What is the tidyverse",
    "text": "What is the tidyverse\n\nwww.tidyverse.com"
  },
  {
    "objectID": "posts4/intro_to_gis.html",
    "href": "posts4/intro_to_gis.html",
    "title": "Intro to GIS for Public Health",
    "section": "",
    "text": "The study of the distribution of Disease and Disease Related States\n\nBy Person\nBy Place\nBy Time"
  },
  {
    "objectID": "posts4/intro_to_gis.html#real-world-to-gis-layers",
    "href": "posts4/intro_to_gis.html#real-world-to-gis-layers",
    "title": "Intro to GIS for Public Health",
    "section": "Real World to GIS Layers",
    "text": "Real World to GIS Layers"
  },
  {
    "objectID": "posts3/General Syntax in R.html",
    "href": "posts3/General Syntax in R.html",
    "title": "Basic Syntax in R",
    "section": "",
    "text": "Symbol\nShortcut\nFormal Name\nRead as\n\n\n\n\n&lt;-\nAlt + (Wiindows)\nOption + (Mac)\nAssignment Operator\nAssign whatever is on the right to the variable on the left.\n\n\n%&gt;%\nCtrl + Shift + M\nPipe (Tidyverse)\nTake this (dataset), and then do this operation\n\n\n” ….”\n\nString\ntext inside quotation marks are usually character or string data type. This is not a rule but a general guideline."
  },
  {
    "objectID": "posts3/verbs_of_the_tidyverse.html#dplyrfilter",
    "href": "posts3/verbs_of_the_tidyverse.html#dplyrfilter",
    "title": "The Verbs of the Tidyverse",
    "section": "dplyr::filter()",
    "text": "dplyr::filter()\nFilter out only rows that meet a particular condition"
  },
  {
    "objectID": "posts3/verbs_of_the_tidyverse.html#dplyrselect",
    "href": "posts3/verbs_of_the_tidyverse.html#dplyrselect",
    "title": "The Verbs of the Tidyverse",
    "section": "dplyr::select()",
    "text": "dplyr::select()\nSelect only columns that meet a particular conditions"
  },
  {
    "objectID": "posts3/verbs_of_the_tidyverse.html#dplyrdistinct",
    "href": "posts3/verbs_of_the_tidyverse.html#dplyrdistinct",
    "title": "The Verbs of the Tidyverse",
    "section": "dplyr::distinct()",
    "text": "dplyr::distinct()\nDeduplicate rows"
  },
  {
    "objectID": "posts3/verbs_of_the_tidyverse.html#janitorclean_names",
    "href": "posts3/verbs_of_the_tidyverse.html#janitorclean_names",
    "title": "The Verbs of the Tidyverse",
    "section": "janitor::clean_names()",
    "text": "janitor::clean_names()\nReplace white spaces with “_” . Remove capitalizations"
  },
  {
    "objectID": "posts3/verbs_of_the_tidyverse.html#dplyrmutate",
    "href": "posts3/verbs_of_the_tidyverse.html#dplyrmutate",
    "title": "The Verbs of the Tidyverse",
    "section": "dplyr::mutate",
    "text": "dplyr::mutate\nRecode values into a new column or same column.\nIf the name of an existing column is used then it recodes into the same column. If a new column name is used it will create a new variable."
  },
  {
    "objectID": "posts3/verbs_of_the_tidyverse.html#case_when",
    "href": "posts3/verbs_of_the_tidyverse.html#case_when",
    "title": "The Verbs of the Tidyverse",
    "section": "case_when()",
    "text": "case_when()\nrecode values into new columns using complex criteria"
  },
  {
    "objectID": "posts3/Loading packages.html#what-are-packages",
    "href": "posts3/Loading packages.html#what-are-packages",
    "title": "Loading Packages",
    "section": "What are packages",
    "text": "What are packages\nPackages are pre-written pieces of code that help make coding efficient.\nContain a variety of functions that can be used .\nThink of it as a kind of “app” for your phone. Your base phone may have a texting service. But sometimes you add an extra app to make it a bit more efficient.\nThese are similar to plugins or extensions in other pieces of software."
  },
  {
    "objectID": "posts3/Loading packages.html#cran",
    "href": "posts3/Loading packages.html#cran",
    "title": "Loading Packages",
    "section": "CRAN",
    "text": "CRAN\nCRAN is a popular place to download packages\nComprehensive R Archive Network\nOfficial Central Repository for the R Language\nAnyone can submit a package to be hosted in CRAN but packages need to adhere to rigorous quality checks and have structured documentation before they are hosted on CRAN.\nPackages are sometimes available from distribtion systems other than CRAN as well."
  },
  {
    "objectID": "posts3/Loading packages.html#using-packages-in-r",
    "href": "posts3/Loading packages.html#using-packages-in-r",
    "title": "Loading Packages",
    "section": "Using packages in R",
    "text": "Using packages in R\nBefore package can be run in R , it needs to be\n\nInstalled on your computer (One time activity)\nLoaded onto the environment (Has to happen everytime)"
  },
  {
    "objectID": "posts3/Loading packages.html#installing-packages",
    "href": "posts3/Loading packages.html#installing-packages",
    "title": "Loading Packages",
    "section": "Installing Packages",
    "text": "Installing Packages\nPackages can be directly downloaded using the command"
  },
  {
    "objectID": "posts3/Loading packages.html#loading-packages",
    "href": "posts3/Loading packages.html#loading-packages",
    "title": "Loading Packages",
    "section": "Loading Packages",
    "text": "Loading Packages"
  },
  {
    "objectID": "posts3/Loading packages.html#recommended-way-of-loading-packages",
    "href": "posts3/Loading packages.html#recommended-way-of-loading-packages",
    "title": "Loading Packages",
    "section": "Recommended way of loading packages",
    "text": "Recommended way of loading packages\nHere we have loaded 3 packages.\nThe “pacman” library helps in managing libraries.\nIt does 2 things\n\nChecks if the package is previously installed AND\nInstalls if needed\nLoads the library\n\nHence it can be a more efficient way to handle packages."
  },
  {
    "objectID": "posts.html#gallery",
    "href": "posts.html#gallery",
    "title": "#30DaysMapChallenge",
    "section": "",
    "text": "This is a brief gallery for some Data Visualization ."
  },
  {
    "objectID": "posts5/datatypes.html",
    "href": "posts5/datatypes.html",
    "title": "Data Types",
    "section": "",
    "text": "In the broadest sense, data is any input that can be structured to provide information and drive action. However, “anything” is too broad for practical work. To navigate data science effectively, we categorize data based on its format and how it can be analyzed.\n1. Unstructured Data\nUnstructured data is increasingly vital in modern science. While we often think of it as simple “string” or “character” fields—such as a “Name” column or an “Other, please describe” box—it encompasses much more.\nModern Machine Learning allows us to extract value from complex unstructured sources, including:\n\nVisuals: X-rays and fundoscopy images.\nAudio: Cough recordings or voice patterns.\nSensors: Real-time data from wearables.\n\nWhile it may seem like magic, it follows a systematic method of converting these “raw” formats into structured data that models can interpret.\n2. Structured Data\nStructured data is a more formal entity, typically stored in a “rectangular” format with variables in columns and cases (or observations) in rows. This data is generally split into two types:\nCategorical\n\nNominal/ Categorical : Data that presents as a category with no inherent rank (e.g., Hair Color or “Diseased/Non-Diseased”). These are typically expressed as counts and percentages.\nOrdinal: A special type of categorical data where there is a logical order (e.g., Mild, Moderate, Severe). When visualizing this data, maintaining that specific sequence is crucial.\n\nNumeric (Quantitative)\n\nContinuous: Variables that can take on decimal values (e.g., weight or blood glucose). These are typically represented by a mean or median.\nDiscrete: Variables that cannot take on decimal places (e.g., Number of Children). Since you cannot have 1.5 children, it only makes logical sense to treat these as whole integers.\n\nSoftware-Specific Nomenclature\nWhile the principles remain constant, the “names” change depending on the tool you use.\n\n\n\n\n\n\n\n\n\nConcept\nIdea\nR Term\nOther Terms\n\n\nFree Text\nAny Text that is typed out in an unstructured way\nCharacter\nString\n\n\nCategorical\nData that can only take a specific set of values (Structured)\nCharacter\nString\n\n\nOrdinal\nCategorical Data that can take a predefined order - example Mild, Moderate, Severe\nFactor\n\n\n\nContinuous\nNumeric Data that can take decimal places\nNumeric\nDouble, Float\n\n\nDiscrete\nNumeric Data that cannot take decimal places\nInteger\nInt\n\n\n\nIn database systems like SQL, terminology becomes even more intricate, with specific types based on precision (total digits) and scale (digits after the decimal). Databases use even more precise datatypes like varchar(50), float(50) etc.\nThe bottom line is that it makes sense to understand how your software processes data and then select the correct data type. This is helpful while cleaning, visualizing or modelling your data and saves you a lot of frustration later in the process."
  },
  {
    "objectID": "posts5.html",
    "href": "posts5.html",
    "title": "Statistics for Data Science",
    "section": "",
    "text": "Exploring Continuous Variables\n\n\n\n\n\n\nDeepak Varughese\n\n\n\n\n\n\n\n\n\n\n\n\nData Types\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkewness and Kurtosis\n\n\n\n\n\n\nDeepak Varughese\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts5/continuous description.html",
    "href": "posts5/continuous description.html",
    "title": "Exploring Continuous Variables",
    "section": "",
    "text": "In these slides we will understand how to describe numeric variables in your dataset.\nWe will explore the ideas of the 4 moments of a dataset\n\nMeasures of Centrality\nMeasures of Spread\nSkewness\nKortusis"
  },
  {
    "objectID": "posts5/continuous description.html#objectives",
    "href": "posts5/continuous description.html#objectives",
    "title": "Exploring Continuous Variables",
    "section": "",
    "text": "In these slides we will understand how to describe numeric variables in your dataset.\nWe will explore the ideas of the 4 moments of a dataset\n\nMeasures of Centrality\nMeasures of Spread\nSkewness\nKortusis"
  },
  {
    "objectID": "posts5/continuous description.html#the-dataset",
    "href": "posts5/continuous description.html#the-dataset",
    "title": "Exploring Continuous Variables",
    "section": "The Dataset",
    "text": "The Dataset\nFor this we will use a clean version of the data present on https://www.kaggle.com/datasets/datasetengineer/public-health-dataset\nThis is a fictional public health dataset and is being used only for educational purposes.\nNote that the data has already been pre-processed and cleaned. Since data cleaning and processing is not the aim of this tutorial we will skip these steps."
  },
  {
    "objectID": "posts5/continuous description.html#loading-the-libraries-and-importing-data.",
    "href": "posts5/continuous description.html#loading-the-libraries-and-importing-data.",
    "title": "Exploring Continuous Variables",
    "section": "Loading the libraries and importing data.",
    "text": "Loading the libraries and importing data.\n\npacman::p_load(\n  tidyverse,\n  here, \n  rio,\n  janitor,\n  skimr,\n  flextable,\n  moments\n)\n\ndata &lt;- import(here(\"posts5\",\"exercise_data_1.csv\"))\n\ndata_clean &lt;- data %&gt;%\n  mutate(across(\n    c(vaccination_status, compliance_with_health_guidelines),\n    ~ factor(\n      case_when(\n        .x == 1 ~ \"Yes\",\n        .x == 0 ~ \"No\"\n      ), \n      levels = c(\"No\", \"Yes\") \n    )))\n\nIn the above steps we can see that we have imported the dataset and then fixed some of the variables so as to be in the correct data types. We now have a new object called data_clean that contains the clean dataset that is ready for analysis. Let us have a look at the dataset\n\nhead(data_clean) %&gt;% \n  flextable()\n\nagegenderlocationethnicitysesvaccination_statustemperatureaqihumiditytravel_historysocial_activitycompliance_with_health_guidelinesreported_symptomstesting_resultsdisease_severityhospitalization_requirement51MaleUrbanEthnicity3LowNo29.3122813331.51287No TravelLowYesMildNegativeMildRequires Hospitalization92MaleUrbanEthnicity2LowNo35.9818312176.88069No TravelMediumYesSevereNegativeMildRequires Hospitalization14MaleUrbanEthnicity3LowYes28.176694286.36421No TravelLowNoNoneNegativeModerateNo Hospitalization71FemaleUrbanEthnicity2LowNo18.5955014228.82366No TravelMediumNoModerateNegativeSevereNo Hospitalization60FemaleUrbanEthnicity1LowNo38.2796923139.47306No TravelMediumYesMildNegativeMildNo Hospitalization20FemaleUrbanEthnicity1LowYes10.862681085.72899InternationalLowYesMildNegativeMildNo Hospitalization\n\n\nWe can now see that the dataset has 16 variables. 12 of these are categorical and 4 of them are numeric. We have explored this in the last tutorial."
  },
  {
    "objectID": "posts5/continuous description.html#exploring-numeric-continuous-variables",
    "href": "posts5/continuous description.html#exploring-numeric-continuous-variables",
    "title": "Exploring Continuous Variables",
    "section": "Exploring Numeric/ Continuous Variables",
    "text": "Exploring Numeric/ Continuous Variables\nA dataset with a continuous variables has rows and rows of data. How do we summarize this data in order for it to make sense to us? In order to describe that variable we need to find a way to collapse all the 43000 rows into some meaningful summary that would make sense to people. Only then can we transform these rows into some meaningful insight that can benefit people.\n\nWe usually do this with the following\n\nMeasures of Centrality and Location\nMeasures of Variability\nMeasures of Shape of the data\nMeasures of Centrality: Finding the “Heart” of Your Data\nWhen we have 43,000 rows of data, we need a single value that represents the “typical” observation. This is the Measure of Centrality.\nThe Mean\n\nWhat is it? It is the sum of all values divided by the total number of observations (\\(n\\)). It represents the mathematical “balance point” of your data.\nWhen to use it: Use the mean when your data is symmetric and has no extreme outliers (e.g., adult height or blood pressure in a healthy population).\nThe “Why” : Most clinical trials report the mean because it is mathematically powerful—it allows for advanced hypothesis testing (like t-tests).\nThe Limitation: It is not “robust.”\n\nExample: You create a 7-minute health education video. If the Mean View Time is 3 minutes, it doesn’t necessarily mean most people watched half the video. It could mean 90% of people clicked away in 5 seconds, but 10% watched it 10 times over. The mean is “dragged” by those few enthusiasts.\n\n\nThe Median\n\nWhat is it? The middle value when all observations are ranked from lowest to highest. It splits your dataset exactly in half.\nWhen to use it: Use the median when your data is skewed or contains outliers.\nThe “Why” (Biomedical Context): In medicine, we often look at “Median Survival Time” or “Length of Stay.”\n\nExample: In a hospital ward, 10 patients stay for 3 days, but one patient with complications stays for 90 days.\n\nMean: ~11 days (misleading; suggests the ward is inefficient).\nMedian: 3 days (accurate; reflects the experience of the “average” patient).\n\n\n\nThe Trimmed Mean\n\nWhat is it? A mean calculated after discarding a small percentage (usually 5% or 10%) of the lowest and highest values.\nWhen to use it: Use it when you want to utilize more data than the median provides, but you want to protect the result from being skewed by “freak” occurrences or measurement errors.\nThe “Why” (Biomedical Context): It is used in situations where “bias” or “noise” is expected at the extremes.\n\nExample: In Olympic diving or gymnastics, the highest and lowest scores are dropped before averaging. In a lab setting, if you run a blood test 10 times and one result is wildly different due to a technical glitch, a trimmed mean ensures that one “glitch” doesn’t ruin your entire average.\n\n\nSummary Table\n\n\n\n\n\n\n\n\nMeasure\nSensitive to Outliers?\nBest Used For…\n\n\nMean\nYes (Highly)\nNormal, bell-shaped data.\n\n\nMedian\nNo (Robust)\nSkewed data (Income, Recovery time).\n\n\nTrimmed Mean\nNo (Limited)\nRemoving “noise” or bias from the extremes.\n\n\n\n\n2. Measures of Variability: How Spread Out is the Data?\n\nIf centrality tells us where the middle is, variability tells us how much the individual patients differ from that middle. High variability means the “average” is less representative of any single patient.\nHow do we now calculate the “Average distance of each value from the mean”?\nCan we simply add all the distances of each point from the mean and then dividing by the number of observations? That would be the logical way to calculate “Average distance from the mean”?\n\nActually no. Let us consider the following scenario.\n\n# 1. Create the dataset\nexample_data &lt;- data.frame(\n  patient_id = as.character(1:10),\n  value = c(2, 3, 4, 4, 5, 5, 6, 6, 7, 8)\n)\n\n# 2. Calculate deviations and squared deviations\ntable_df &lt;- example_data %&gt;%\n  mutate(\n    mean = mean(value),\n    distance_from_mean = value - mean\n  ) %&gt;% \n  flextable()\n\ntable_df\n\npatient_idvaluemeandistance_from_mean125-3235-2345-1445-15550655076518651975210853\n\n\nIf we add all the distance from the mean and now take and average we will actually get “Zero”!\nThis is because for every positive difference from the mean we now have a negative value from the mean. This would keep our net difference as zero simply because that is how addition and algebra work.\n\nTo counter this we now need a strategy to remove the negative sign for the values below zero.\n\nTo do this we can use two mathematical approaches\nSquare the values - Variance and Standard Deviation\nTake the absolute values and remove the negative sign - Mean Absolute Deviation / Median Absolute Deviation\nUse a location based estimate similar to the median (Interquartile Range)\nVariance (\\(s^2\\)) and Standard Deviation\n\nWhat is it?\nTake the square of each value for distance from the mean. This will automatically remove the negative sign. Now divide this number by the number of observations. This is your variance. This is however difficult to interpret as the scale and units are now in “square units”. To convert it back to the original scale we now take the square root of the variance. This is our Standard Deviation.\nWhen to use it: Variance is rarely reported directly. However it powers many statistical tests. The more commonly used statistic is the standard deviation. Whenever the mean is reported, it must always be accompanied by a report of standard deviation.\n“Why”: Standard Deviation is much more sensitive to values that are far away from the mean. Because you are squaring the distances, a point that is 4 units away contributes 16 to the variance, while a point 2 units away only contributes 4. This can be important in cases where small fluctuations are important.\n\nExample: Imagine you are monitoring a patient’s heart rate. If the rate fluctuates slightly, it’s fine. But if it occasionally spikes wildly, you want a metric that “screams” when those spikes happen. SD screams louder than MAD because it squares those extreme gaps, alerting the researcher to high instability.\n\nMean Absolute Deviation (MAD) or Median Absolute Deviation (MedAD)\n\nWhat is it?\nThese measures use another approach to get rid of the negative sign. They simply use the absolute values ignoring the negative sign. They look at the absolute distance of each point from the center (Mean or Median) without squaring them.\nThe “Why” and When\nSquaring the differences (as in Variance/SD) gives massive weight to outliers. MAD does not do this and gives a more even estimate. When to use what will depend on how important the outliers are to the dataset.\n\nMAD were traditionally not used much in statistics because their use in inferential statistics etc can be computationally intensive. Since traditional statistics were done using calculus , pen and paper the standard deviation was always used. However MAD can be a more intuitive measure and is quickly gaining importance in data science especially in finance and other domains.\n\n\nInterquartile Range (IQR)\n\nWhat is it?\nSuppose we were to list out all the values in the dataset in ascending order and divide them into 4 equal groups. The first group is from 0 to 25% of the values. The second from 25 to 50% of values. The third is the 50th to 75th percent of values and the last from 75th to 100 percent of values. These are called the 4 quartiles of the variable. The Interquartile range is the difference between where the 2nd Quartile Starts and the 3rd Quartile ends. Essentially it would contain 50% of the values.\nWhen to use it: Always use this when you are reporting a Median. It is the “robust” partner to the median.\nThe “Why”: Like the median, the IQR is not affected by extreme outliers.\n\npatient_data &lt;- data.frame(\n  Value = c(2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 12, 15, 18, 22, 30)\n) %&gt;% \n  arrange(Value) %&gt;%\n  mutate(Patient_ID = row_number())\n\n\npatient_data &lt;- patient_data %&gt;%\n  mutate(\n    Quartile = case_when(\n      Patient_ID &lt;= 4  ~ \"Q1 (0-25%)\",\n      Patient_ID &lt;= 8  ~ \"Q2 (25-50%)\",\n      Patient_ID &lt;= 12 ~ \"Q3 (50-75%)\",\n      TRUE             ~ \"Q4 (75-100%)\"\n    )\n  )\n\n# 3. Create the table\npatient_data %&gt;%\n  select(Patient_ID, Value, Quartile) %&gt;%\n  flextable() %&gt;%\n  set_header_labels(\n    Patient_ID = \"Patient Rank\",\n    Value = \"Recovery Days\",\n    Quartile = \"Quartile Group\"\n  ) %&gt;%\n  # Color-code the quartiles to show the 4 distinct groups\n  bg(i = 1:4, bg = \"#E1F5FE\", part = \"body\") %&gt;%\n  bg(i = 5:8, bg = \"#B3E5FC\", part = \"body\") %&gt;%\n  bg(i = 9:12, bg = \"#81D4FA\", part = \"body\") %&gt;%\n  bg(i = 13:16, bg = \"#4FC3F7\", part = \"body\") %&gt;%\n  # Highlight the boundaries for IQR (Q1 and Q3)\n  bold(i = c(4, 12), j = 2) %&gt;%\n  add_footer_lines(\"The IQR is the range between the end of Q1 (4 days) and the end of Q3 (12 days).\") %&gt;%\n  autofit()\n\nPatient RankRecovery DaysQuartile Group12Q1 (0-25%)23Q1 (0-25%)33Q1 (0-25%)44Q1 (0-25%)55Q2 (25-50%)65Q2 (25-50%)76Q2 (25-50%)87Q2 (25-50%)98Q3 (50-75%)109Q3 (50-75%)1110Q3 (50-75%)1212Q3 (50-75%)1315Q4 (75-100%)1418Q4 (75-100%)1522Q4 (75-100%)1630Q4 (75-100%)The IQR is the range between the end of Q1 (4 days) and the end of Q3 (12 days).\n\n\n\nExample:\nConsider the above example which looks at days of recovery for In-Patients at a ward. Notice how the IQR of 4-12 was calculated.\n\n\nCoefficient of Variation (CV)\n\nWhat is it?\nThe Coefficient of Variance is a bit different from everything we discussed. It is not measure of variability in the way the other variables here have been discussed. It is he ratio of the Standard Deviation to the Mean \\((SD / Mean)\\), often expressed as a percentage.\nWhen to use it:\nThe CV is used to compare the variability of two different variables that have different units or wildly different scales. The standard deviations of 2 different variables cannot be directly compared as they may be measured on different scales and units. We now need a way to normalize this. This is done by dividing by mean and therefore removing the scale from the equation.\nThe “Why”: It provides a “normalized” measure of spread.\n\nSuppose you want to know if a patient’s Cholesterol is more unstable than their Body Weight. You can’t compare “mg/dL” to “kg” directly.\n\nWeight: Mean = 80kg, SD = 2kg \\(\\rightarrow\\) CV = 2.5%\nCholesterol: Mean = 200mg/dL, SD = 20mg/dL \\(\\rightarrow\\) CV = 10%\n\nInterpretation: Even though the SD for cholesterol (20) looks much bigger than the SD for weight (2), the cholesterol is actually four times more variable relative to its average.\n\n\n# Comparing Weight vs Cholesterol Variability\ncomparison &lt;- data.frame(\n  Metric = c(\"Body Weight (kg)\", \"Cholesterol (mg/dL)\"),\n  Mean = c(80, 200),\n  SD = c(2, 20)\n) %&gt;%\n  mutate(CV = (SD / Mean) * 100)\n\ncomparison %&gt;%\n  flextable() %&gt;%\n  set_header_labels(CV = \"CV (%)\") %&gt;%\n  colformat_double(digits = 1) %&gt;%\n  set_caption(\"Table: Using CV to Compare Variability Across Different Scales\")\n\nMetricMeanSDCV (%)Body Weight (kg)80.02.02.5Cholesterol (mg/dL)200.020.010.0\n\n\n\nSummary Table for Students\n\n\n\n\n\n\n\n\n\nMeasure\nPair it with\nUnit of Measure\nBest for…\n\n\nStandard Deviation\nMean\nSame as data (e.g., mmHg)\nNormal distributions.\n\n\nIQR\nMedian\nSame as data (e.g., days)\nSkewed data/Clinical stay.\n\n\nCV\nN/A\nPercentage (%)\nComparing consistency across different scales.\n\n\n\nWe will look at measures of the spread of the data in the next tutorial"
  },
  {
    "objectID": "posts5/continuous description.html#we-usually-do-this-with-the-following",
    "href": "posts5/continuous description.html#we-usually-do-this-with-the-following",
    "title": "Exploring Continuous Variables",
    "section": "We usually do this with the following",
    "text": "We usually do this with the following\n\nMeasures of Centrality and Location\nMeasures of Variability\nMeasures of Shape of the data\n1. Measures of Centrality: Finding the “Heart” of Your Data\nWhen we have 43,000 rows of data, we need a single value that represents the “typical” observation. This is the Measure of Centrality.\nThe Mean\n\nWhat is it? It is the sum of all values divided by the total number of observations (\\(n\\)). It represents the mathematical “balance point” of your data.\nWhen to use it: Use the mean when your data is symmetric and has no extreme outliers (e.g., adult height or blood pressure in a healthy population).\nThe “Why” : Most clinical trials report the mean because it is mathematically powerful—it allows for advanced hypothesis testing (like t-tests).\nThe Limitation: It is not “robust.”\n\nExample: You create a 7-minute health education video. If the Mean View Time is 3 minutes, it doesn’t necessarily mean most people watched half the video. It could mean 90% of people clicked away in 5 seconds, but 10% watched it 10 times over. The mean is “dragged” by those few enthusiasts.\n\n\nThe Median\n\nWhat is it? The middle value when all observations are ranked from lowest to highest. It splits your dataset exactly in half.\nWhen to use it: Use the median when your data is skewed or contains outliers.\nThe “Why” (Biomedical Context): In medicine, we often look at “Median Survival Time” or “Length of Stay.”\n\nExample: In a hospital ward, 10 patients stay for 3 days, but one patient with complications stays for 90 days.\n\nMean: ~11 days (misleading; suggests the ward is inefficient).\nMedian: 3 days (accurate; reflects the experience of the “average” patient).\n\n\n\nThe Trimmed Mean\n\nWhat is it? A mean calculated after discarding a small percentage (usually 5% or 10%) of the lowest and highest values.\nWhen to use it: Use it when you want to utilize more data than the median provides, but you want to protect the result from being skewed by “freak” occurrences or measurement errors.\nThe “Why” (Biomedical Context): It is used in situations where “bias” or “noise” is expected at the extremes.\n\nExample: In Olympic diving or gymnastics, the highest and lowest scores are dropped before averaging. In a lab setting, if you run a blood test 10 times and one result is wildly different due to a technical glitch, a trimmed mean ensures that one “glitch” doesn’t ruin your entire average.\n\n\nSummary Table\n\n\n\n\n\n\n\n\nMeasure\nSensitive to Outliers?\nBest Used For…\n\n\nMean\nYes (Highly)\nNormal, bell-shaped data.\n\n\nMedian\nNo (Robust)\nSkewed data (Income, Recovery time).\n\n\nTrimmed Mean\nNo (Limited)\nRemoving “noise” or bias from the extremes.\n\n\n\n\n2. Measures of Variability: How Spread Out is the Data?\n\nIf centrality tells us where the middle is, variability tells us how much the individual patients differ from that middle. High variability means the “average” is less representative of any single patient.\nHow do we now calculate the “Average distance of each value from the mean”?\nCan we simply add all the distances of each point from the mean and then dividing by the number of observations? That would be the logical way to calculate “Average distance from the mean”?\n\nActually no. Let us consider the following scenario.\n\n# 1. Create the dataset\nexample_data &lt;- data.frame(\n  patient_id = as.character(1:10),\n  value = c(2, 3, 4, 4, 5, 5, 6, 6, 7, 8)\n)\n\n# 2. Calculate deviations and squared deviations\ntable_df &lt;- example_data %&gt;%\n  mutate(\n    mean = mean(value),\n    distance_from_mean = value - mean\n  ) %&gt;% \n  flextable()\n\ntable_df\n\npatient_idvaluemeandistance_from_mean125-3235-2345-1445-15550655076518651975210853\n\n\nIf we add all the distance from the mean and now take and average we will actually get “Zero”!\nThis is because for every positive difference from the mean we now have a negative value from the mean. This would keep our net difference as zero simply because that is how addition and algebra work.\n\nTo counter this we now need a strategy to remove the negative sign for the values below zero.\n\nTo do this we can use two mathematical approaches\nSquare the values - Variance and Standard Deviation\nTake the absolute values and remove the negative sign - Mean Absolute Deviation / Median Absolute Deviation\nUse a location based estimate similar to the median (Interquartile Range)\nVariance (\\(s^2\\)) and Standard Deviation\n\nWhat is it?\nTake the square of each value for distance from the mean. This will automatically remove the negative sign. Now divide this number by the number of observations. This is your variance. This is however difficult to interpret as the scale and units are now in “square units”. To convert it back to the original scale we now take the square root of the variance. This is our Standard Deviation.\nWhen to use it: Variance is rarely reported directly. However it powers many statistical tests. The more commonly used statistic is the standard deviation. Whenever the mean is reported, it must always be accompanied by a report of standard deviation.\n“Why”: Standard Deviation is much more sensitive to values that are far away from the mean. Because you are squaring the distances, a point that is 4 units away contributes 16 to the variance, while a point 2 units away only contributes 4. This can be important in cases where small fluctuations are important.\n\nExample: Imagine you are monitoring a patient’s heart rate. If the rate fluctuates slightly, it’s fine. But if it occasionally spikes wildly, you want a metric that “screams” when those spikes happen. SD screams louder than MAD because it squares those extreme gaps, alerting the researcher to high instability.\n\nMean Absolute Deviation (MAD) or Median Absolute Deviation (MedAD)\n\nWhat is it?\nThese measures use another approach to get rid of the negative sign. They simply use the absolute values ignoring the negative sign. They look at the absolute distance of each point from the center (Mean or Median) without squaring them.\nThe “Why” and When\nSquaring the differences (as in Variance/SD) gives massive weight to outliers. MAD does not do this and gives a more even estimate. When to use what will depend on how important the outliers are to the dataset.\n\nMAD were traditionally not used much in statistics because their use in inferential statistics etc can be computationally intensive. Since traditional statistics were done using calculus , pen and paper the standard deviation was always used. However MAD can be a more intuitive measure and is quickly gaining importance in data science especially in finance and other domains.\n\n\nInterquartile Range (IQR)\n\nWhat is it?\nSuppose we were to list out all the values in the dataset in ascending order and divide them into 4 equal groups. The first group is from 0 to 25% of the values. The second from 25 to 50% of values. The third is the 50th to 75th percent of values and the last from 75th to 100 percent of values. These are called the 4 quartiles of the variable. The Interquartile range is the difference between where the 2nd Quartile Starts and the 3rd Quartile ends. Essentially it would contain 50% of the values.\nWhen to use it: Always use this when you are reporting a Median. It is the “robust” partner to the median.\nThe “Why”: Like the median, the IQR is not affected by extreme outliers.\n\npatient_data &lt;- data.frame(\n  Value = c(2, 3, 3, 4, 5, 5, 6, 7, 8, 9, 10, 12, 15, 18, 22, 30)\n) %&gt;% \n  arrange(Value) %&gt;%\n  mutate(Patient_ID = row_number())\n\n\npatient_data &lt;- patient_data %&gt;%\n  mutate(\n    Quartile = case_when(\n      Patient_ID &lt;= 4  ~ \"Q1 (0-25%)\",\n      Patient_ID &lt;= 8  ~ \"Q2 (25-50%)\",\n      Patient_ID &lt;= 12 ~ \"Q3 (50-75%)\",\n      TRUE             ~ \"Q4 (75-100%)\"\n    )\n  )\n\n# 3. Create the table\npatient_data %&gt;%\n  select(Patient_ID, Value, Quartile) %&gt;%\n  flextable() %&gt;%\n  set_header_labels(\n    Patient_ID = \"Patient Rank\",\n    Value = \"Recovery Days\",\n    Quartile = \"Quartile Group\"\n  ) %&gt;%\n  # Color-code the quartiles to show the 4 distinct groups\n  bg(i = 1:4, bg = \"#E1F5FE\", part = \"body\") %&gt;%\n  bg(i = 5:8, bg = \"#B3E5FC\", part = \"body\") %&gt;%\n  bg(i = 9:12, bg = \"#81D4FA\", part = \"body\") %&gt;%\n  bg(i = 13:16, bg = \"#4FC3F7\", part = \"body\") %&gt;%\n  # Highlight the boundaries for IQR (Q1 and Q3)\n  bold(i = c(4, 12), j = 2) %&gt;%\n  add_footer_lines(\"The IQR is the range between the end of Q1 (4 days) and the end of Q3 (12 days).\") %&gt;%\n  autofit()\n\nPatient RankRecovery DaysQuartile Group12Q1 (0-25%)23Q1 (0-25%)33Q1 (0-25%)44Q1 (0-25%)55Q2 (25-50%)65Q2 (25-50%)76Q2 (25-50%)87Q2 (25-50%)98Q3 (50-75%)109Q3 (50-75%)1110Q3 (50-75%)1212Q3 (50-75%)1315Q4 (75-100%)1418Q4 (75-100%)1522Q4 (75-100%)1630Q4 (75-100%)The IQR is the range between the end of Q1 (4 days) and the end of Q3 (12 days).\n\n\n\nExample:\nConsider the above example which looks at days of recovery for In-Patients at a ward. Notice how the IQR of 4-12 was calculated.\n\n\nCoefficient of Variation (CV)\n\nWhat is it?\nThe Coefficient of Variance is a bit different from everything we discussed. It is not measure of variability in the way the other variables here have been discussed. It is he ratio of the Standard Deviation to the Mean \\((SD / Mean)\\), often expressed as a percentage.\nWhen to use it:\nThe CV is used to compare the variability of two different variables that have different units or wildly different scales. The standard deviations of 2 different variables cannot be directly compared as they may be measured on different scales and units. We now need a way to normalize this. This is done by dividing by mean and therefore removing the scale from the equation.\nThe “Why”: It provides a “normalized” measure of spread.\n\nSuppose you want to know if a patient’s Cholesterol is more unstable than their Body Weight. You can’t compare “mg/dL” to “kg” directly.\n\nWeight: Mean = 80kg, SD = 2kg \\(\\rightarrow\\) CV = 2.5%\nCholesterol: Mean = 200mg/dL, SD = 20mg/dL \\(\\rightarrow\\) CV = 10%\n\nInterpretation: Even though the SD for cholesterol (20) looks much bigger than the SD for weight (2), the cholesterol is actually four times more variable relative to its average.\n\n\n# Comparing Weight vs Cholesterol Variability\ncomparison &lt;- data.frame(\n  Metric = c(\"Body Weight (kg)\", \"Cholesterol (mg/dL)\"),\n  Mean = c(80, 200),\n  SD = c(2, 20)\n) %&gt;%\n  mutate(CV = (SD / Mean) * 100)\n\ncomparison %&gt;%\n  flextable() %&gt;%\n  set_header_labels(CV = \"CV (%)\") %&gt;%\n  colformat_double(digits = 1) %&gt;%\n  set_caption(\"Table: Using CV to Compare Variability Across Different Scales\")\n\nMetricMeanSDCV (%)Body Weight (kg)80.02.02.5Cholesterol (mg/dL)200.020.010.0\n\n\n\nSummary Table for Students\n\n\n\n\n\n\n\n\n\nMeasure\nPair it with\nUnit of Measure\nBest for…\n\n\nStandard Deviation\nMean\nSame as data (e.g., mmHg)\nNormal distributions.\n\n\nIQR\nMedian\nSame as data (e.g., days)\nSkewed data/Clinical stay.\n\n\nCV\nN/A\nPercentage (%)\nComparing consistency across different scales.\n\n\n\nWe will look at measures of the spread of the data in the next tutorial"
  },
  {
    "objectID": "posts5/skewness and kurtosis.html",
    "href": "posts5/skewness and kurtosis.html",
    "title": "Skewness and Kurtosis",
    "section": "",
    "text": "In this tutorial we will\n\nAnalyze how to understand Skewness and Kurtosis"
  },
  {
    "objectID": "posts5/skewness and kurtosis.html#objectives",
    "href": "posts5/skewness and kurtosis.html#objectives",
    "title": "Skewness and Kurtosis",
    "section": "",
    "text": "In this tutorial we will\n\nAnalyze how to understand Skewness and Kurtosis"
  },
  {
    "objectID": "posts5/skewness and kurtosis.html#introduction",
    "href": "posts5/skewness and kurtosis.html#introduction",
    "title": "Skewness and Kurtosis",
    "section": "Introduction",
    "text": "Introduction\nIn the last tutorial we talked about measures of centrality and dispersion. Often we are tempted to stop at that. However to truely understand our continuous variable we also have to understand the skewness and kurtosis of our dataset. A dataset in which a mean = median may not always be normally distributed unless we can verify the skew and kurtosis of the data. So let us try to understand what this measures mean"
  },
  {
    "objectID": "posts5/skewness and kurtosis.html#example",
    "href": "posts5/skewness and kurtosis.html#example",
    "title": "Skewness and Kurtosis",
    "section": "Example",
    "text": "Example\n\n\nVariableMeanMedianSDVarianceSkewExcess_KurtVariable 150.050.010.0100.60.00.0Variable 250.050.012.9165.8-0.16.0Variable 350.050.117.3301.00.0-1.2Variable 438.036.86.137.21.00.9Variable 562.163.36.136.9-1.00.9\n\n\nConsider the above table. Focus on just the mean and the median. By just looking at these two values, we can judge skew. But its hard to quantify it mathematically and decide how much skew is present but its easy to spot a positive or negative skew by simply looking at the difference between the mean and median. This should alert us to the possibility of a skew in case we do not routinely look for it.\n\nVariables 1 to 3 all have a similar mean. A common mistake is to now assume that all 3 of them are normally distributed. Afterall mean = median is a property of a normal distribution. However if you look at the table again you will notice that Variable 2 has a Kurtosis of 6 and Variable 3 has a Kurtosis of -1.2. Variable 1 has a Kurtosis of 0.\nTo understand this let us now actually plot the distributions and see.\n\n\n\n\n\n\n\n\n\n\nLook at the variables titled High Kurtosis and Low Kurtosis.\nKurtosis refers to how much data is present in the “tails” of the data. For the next part of the passage on how much of the data is present outside the 2 red lines in the figure that signify the 2 * SD mark.\nIn a normal distribution 95% of the values lie between 2 standard deviation from the mean. 2.5 % lie below -2SD and 2.5% lie above +2SD. (A total of 5% of values lie in the “tails”).\nHowever in distributions with high kurtosis you will find a high peak in the centre and more than 5% of values lying in the tails. This is known as the “heavy tails”. These distributions are referred to as “leptokutotic” distributions.\nIn distributions with low kurtosis you find an almost flat distribution with all the values getting over even before reaching the 2SD. This is called the platykurtotic distribution. These distributions have “thin tails”.\nIn summary - skewness gives you information on the asymettry of the data and kurtosis gives you information on how much information is present in the tails of the data."
  },
  {
    "objectID": "posts5/skewness and kurtosis.html#skew",
    "href": "posts5/skewness and kurtosis.html#skew",
    "title": "Skewness and Kurtosis",
    "section": "Skew",
    "text": "Skew\nThe skew of a distribution is a measure of its assymetry. Variables that have a few extreme values are skewed distributions.\nIf there are a few extremely large values the data is called right skewed. The mean will shift to a larger value on account of the few large values. Visually on a histogram this looks like the histogram stretching to the right (hence the name “Right Skew). A quick way to suspect a right skewed distribution is when the mean is larger than the median.\nConversely if there a few extremely small values. The data is left skewed. The mean will be less than the median.\n\nMathematically skew is represented as either a positive or negative number. Positive numbers indicates a left skew and negative numbers indicate a left skew. There is no universal standard while interpreting the strength of the skew. However values from 0 to plus or minus 0.5 are not necessarily considered skew. Less than -0.5 or more than +0.5 are moderate skewed. Less than -1 or more than +1 are considered extremely skewed."
  },
  {
    "objectID": "posts5/skewness_kurtosis.html",
    "href": "posts5/skewness_kurtosis.html",
    "title": "Skewness and Kurtosis",
    "section": "",
    "text": "In this tutorial we will\n\nAnalyze how to understand Skewness and Kurtosis"
  },
  {
    "objectID": "posts5/skewness_kurtosis.html#objectives",
    "href": "posts5/skewness_kurtosis.html#objectives",
    "title": "Skewness and Kurtosis",
    "section": "",
    "text": "In this tutorial we will\n\nAnalyze how to understand Skewness and Kurtosis"
  },
  {
    "objectID": "posts5/skewness_kurtosis.html#introduction",
    "href": "posts5/skewness_kurtosis.html#introduction",
    "title": "Skewness and Kurtosis",
    "section": "Introduction",
    "text": "Introduction\nIn the last tutorial we talked about measures of centrality and dispersion. Often we are tempted to stop at that. However to truely understand our continuous variable we also have to understand the skewness and kurtosis of our dataset. A dataset in which a mean = median may not always be normally distributed unless we can verify the skew and kurtosis of the data. So let us try to understand what this measures mean"
  },
  {
    "objectID": "posts5/skewness_kurtosis.html#skew",
    "href": "posts5/skewness_kurtosis.html#skew",
    "title": "Skewness and Kurtosis",
    "section": "Skew",
    "text": "Skew\nThe skew of a distribution is a measure of its assymetry. Variables that have a few extreme values are skewed distributions.\nIf there are a few extremely large values the data is called right skewed. The mean will shift to a larger value on account of the few large values. Visually on a histogram this looks like the histogram stretching to the right (hence the name “Right Skew). A quick way to suspect a right skewed distribution is when the mean is larger than the median.\nConversely if there a few extremely small values. The data is left skewed. The mean will be less than the median.\n\nMathematically skew is represented as either a positive or negative number. Positive numbers indicates a left skew and negative numbers indicate a left skew. There is no universal standard while interpreting the strength of the skew. However values from 0 to plus or minus 0.5 are not necessarily considered skew. Less than -0.5 or more than +0.5 are moderate skewed. Less than -1 or more than +1 are considered extremely skewed."
  },
  {
    "objectID": "posts5/skewness_kurtosis.html#example",
    "href": "posts5/skewness_kurtosis.html#example",
    "title": "Skewness and Kurtosis",
    "section": "Example",
    "text": "Example\n\n\nVariableMeanMedianSDVarianceSkewExcess_KurtVariable 150.050.010.0100.60.00.0Variable 250.050.012.9165.8-0.16.0Variable 350.050.117.3301.00.0-1.2Variable 438.036.86.137.21.00.9Variable 562.163.36.136.9-1.00.9\n\n\nConsider the above table. Focus on just the mean and the median. By just looking at these two values, we can judge skew. But its hard to quantify it mathematically and decide how much skew is present but its easy to spot a positive or negative skew by simply looking at the difference between the mean and median. This should alert us to the possibility of a skew in case we do not routinely look for it.\n\nVariables 1 to 3 all have a similar mean. A common mistake is to now assume that all 3 of them are normally distributed. Afterall mean = median is a property of a normal distribution. However if you look at the table again you will notice that Variable 2 has a Kurtosis of 6 and Variable 3 has a Kurtosis of -1.2. Variable 1 has a Kurtosis of 0.\nTo understand this let us now actually plot the distributions and see."
  },
  {
    "objectID": "posts5/skewness_kurtosis.html#kurtosis",
    "href": "posts5/skewness_kurtosis.html#kurtosis",
    "title": "Skewness and Kurtosis",
    "section": "Kurtosis",
    "text": "Kurtosis\nLook at the variables titled High Kurtosis and Low Kurtosis.\nKurtosis refers to how much data is present in the “tails” of the data. For the next part of the passage on how much of the data is present outside the 2 red lines in the figure that signify the 2 * SD mark.\nIn a normal distribution 95% of the values lie between 2 standard deviation from the mean. 2.5 % lie below -2SD and 2.5% lie above +2SD. (A total of 5% of values lie in the “tails”).\nHowever in distributions with high kurtosis you will find a high peak in the centre and more than 5% of values lying in the tails. This is known as the “heavy tails”. These distributions are referred to as “leptokutotic” distributions.\nIn distributions with low kurtosis you find an almost flat distribution with all the values getting over even before reaching the 2SD. This is called the platykurtotic distribution. These distributions have “thin tails”.\nIn summary - skewness gives you information on the asymettry of the data and kurtosis gives you information on how much information is present in the tails of the data.\n\nWhy this becomes important is because a skewed or kurtotic distribution needs to be handled differently in analysis.\nIn a flat platykurtotic distribution for example , even though there is technically a mean you dont really see much clustering around the mean. In fact the example that we see in our figure is that of a flat distribution that has very different properties from that of a normal distribution.\nIn a platykurtotic distribution , most values are tightly clustered around each other. But extreme events can happen far more frequently than a normal curve would predict. These are often called “Black Swan” events.\nExample\nTo understand a bit better let us use a sporting example. In cricket , a batter who has a career average of 25 would consistently score between 25 and 45. In this scenario a normal curve would predict a score of 100 or 0 to be a very rare event. However we know that this is not how it works out in the real world. 100s and 0s do happen.\n\n# Simulated career scores: High frequency of low scores + rare massive scores\nscores &lt;- c(rep(0:20, 5), 35, 42, 55, 68, 110, 150, 210, 319)\n\n\n\n# Calculate Kurtosis\n# A normal distribution has a kurtosis of 3. \n# Anything significantly higher is Leptokurtic.\nkurt_val &lt;- kurtosis(scores)\ncat(\"The Kurtosis of these scores is:\", round(kurt_val, 2))\n\nThe Kurtosis of these scores is: 35.82\n\n# Plotting the distribution\nggplot(data.frame(scores), aes(x = scores)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_vline(aes(xintercept = mean(scores)), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = mean(scores) + 40, y = 0.02, label = \"Mean Score\", color = \"red\") +\n  labs(title = \"Batting scores per game scored by a batter across a career\",\n       subtitle = paste(\"Excessive 'Fat' Tail reaching toward 300+ runs\"),\n       x = \"Runs Scored\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis is an example of a variable that is both skewed and leptokurtotic. This does happen in real life. Unlike the neat example given in the initial set of figures you know have a combination of skew and kurtosis all coming together."
  }
]